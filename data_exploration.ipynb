{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "29d4eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "99039533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e02a0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ### Load all three JSON datasets and merge into single dict ###\n",
    "    filenames = ['recipes_raw_nosource_ar.json', 'recipes_raw_nosource_epi.json', 'recipes_raw_nosource_fn.json']\n",
    "    websites = ['AllRecipes', 'FoodNetwork', 'Epicurious']\n",
    "    abv = ['AR', 'FN', 'EP']\n",
    "    \n",
    "    full_data = []\n",
    "    i = 0\n",
    "    for file in filenames:\n",
    "        with open('recipes_raw/'+file) as f:\n",
    "            raw = json.load(f)\n",
    "        data = list(raw.values())\n",
    "        \n",
    "        # add key for website scraped from\n",
    "        for recipe in data:\n",
    "            recipe['website'] = abv[i]\n",
    "        \n",
    "        full_data += list(data)\n",
    "        \n",
    "        # print statistics with regards to each dataset ##\n",
    "        print('----------------')\n",
    "        print(file)\n",
    "        print('Total recipes from {} : {}'.format(websites[i], len(data)))\n",
    "        print('Dictionary keys: {} \\n'.format(data[0].keys()))\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print('----------------')\n",
    "    print('Total recipes across all three websites: {}'.format(len(full_data)))\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0a6f6759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "recipes_raw_nosource_ar.json\n",
      "Total recipes from AllRecipes : 39802\n",
      "Dictionary keys: dict_keys(['title', 'ingredients', 'instructions', 'picture_link', 'website']) \n",
      "\n",
      "----------------\n",
      "recipes_raw_nosource_epi.json\n",
      "Total recipes from FoodNetwork : 25323\n",
      "Dictionary keys: dict_keys(['ingredients', 'picture_link', 'instructions', 'title', 'website']) \n",
      "\n",
      "----------------\n",
      "recipes_raw_nosource_fn.json\n",
      "Total recipes from Epicurious : 60039\n",
      "Dictionary keys: dict_keys(['instructions', 'ingredients', 'title', 'picture_link', 'website']) \n",
      "\n",
      "----------------\n",
      "Total recipes across all three websites: 125164\n"
     ]
    }
   ],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d038baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data preprocessing\n",
    "def preprocessing(data):\n",
    "    ### Remove all entries without title, ingredients, or instructions ###\n",
    "    init_len = len(data)\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    \n",
    "    # keep track of recipe index\n",
    "    i = 0\n",
    "    for recipe in data:\n",
    "        title = recipe.get('title')\n",
    "        ingredients = recipe.get('ingredients')\n",
    "        instructions = recipe.get('instructions')\n",
    "        \n",
    "        # if any of the three keys are blank, remove recipe from dataset\n",
    "        if(not title or not ingredients or not instructions):\n",
    "            del data_copy[i]\n",
    "        else: # when element is deleted, index is removed\n",
    "            i += 1 \n",
    "        \n",
    "        \n",
    "    post_len = len(data_copy) \n",
    "    \n",
    "    print('Preprocessing: \\n----------------')\n",
    "    print('Number of samples prior to preprocessing: {}'.format(init_len))\n",
    "    print('Number of samples post preprocessing: {}'.format(post_len))\n",
    "    print('Total number of recipes removed: {}'.format(init_len-post_len))\n",
    "    \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3353598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing: \n",
      " ----------------\n",
      "Number of samples prior to preprocessing: 125164\n",
      "Number of samples post preprocessing: 122938\n",
      "Total number of recipes removed: 2226\n",
      "---------------- \n",
      "\n",
      "SAMPLE RECIPE \n",
      "----------------\n",
      "title : Slow Cooker Chicken and Dumplings \n",
      "\n",
      "ingredients : ['4 skinless, boneless chicken breast halves ADVERTISEMENT', '2 tablespoons butter ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of chicken soup ADVERTISEMENT', '1 onion, finely diced ADVERTISEMENT', '2 (10 ounce) packages refrigerated biscuit dough, torn into pieces ADVERTISEMENT', 'ADVERTISEMENT'] \n",
      "\n",
      "instructions : Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\n",
      "Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\n",
      " \n",
      "\n",
      "picture_link : 55lznCYBbs2mT8BTx6BTkLhynGHzM.S \n",
      "\n",
      "website : AR \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_complete = preprocessing(data)\n",
    "\n",
    "print('---------------- \\n')\n",
    "print('SAMPLE RECIPE \\n----------------')\n",
    "for i in data_complete[0]:\n",
    "    print(i, ': {} \\n'.format(data_complete[0].get(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "51b6d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration(data):\n",
    "    # find highest word frequencies of ingredients\n",
    "    all_ing = []\n",
    "    \n",
    "    i = 0\n",
    "    for recipe in data:\n",
    "        ingredients = recipe.get('ingredients')\n",
    "        all_ing += ingredients\n",
    "        \n",
    "    # top 15 most frequent ingredient strings\n",
    "    counter = Counter(all_ing)\n",
    "    top15 = counter.most_common()[:15]\n",
    "    \n",
    "    print('Top 15 most frequent ingredient strings: ')\n",
    "    print('----------------')\n",
    "    \n",
    "    for string in top15:\n",
    "        print(string[0], ' --> Count: ', string[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "88ee3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most frequent ingredient strings: \n",
      "----------------\n",
      "ADVERTISEMENT  --> Count:  39519\n",
      "Salt and freshly ground black pepper  --> Count:  5218\n",
      "Kosher salt and freshly ground black pepper  --> Count:  4886\n",
      "Kosher salt  --> Count:  4844\n",
      "1/2 teaspoon salt  --> Count:  4246\n",
      "1/2 teaspoon salt ADVERTISEMENT  --> Count:  3455\n",
      "1 teaspoon salt  --> Count:  3372\n",
      "2 tablespoons olive oil  --> Count:  3353\n",
      "Salt and pepper  --> Count:  3203\n",
      "Salt  --> Count:  3039\n",
      "Freshly ground black pepper  --> Count:  3026\n",
      "1 teaspoon vanilla extract ADVERTISEMENT  --> Count:  2998\n",
      "1 teaspoon salt ADVERTISEMENT  --> Count:  2969\n",
      "1/4 teaspoon salt  --> Count:  2889\n",
      "salt and pepper to taste ADVERTISEMENT  --> Count:  2457\n"
     ]
    }
   ],
   "source": [
    "exploration(data_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8924ca",
   "metadata": {},
   "source": [
    "1) Need to get ride of 'ADVERTISEMENT' as it is present in almost every string.  \n",
    "2) 11 of 15 top strings contain SALT. Need to strip down strings to individual words to get a better sense of most used ingredients. Clearly, salt is number 1.  \n",
    "3) For Word2Vec representation, we need to eliminate all STOP words and measurements - 1/2 tsp salt --> salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e25f1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of common measurements ##\n",
    "measurements = ['teaspon',\n",
    "               'dessertspoon',\n",
    "               'tablespoon',\n",
    "               'fluid ounce',\n",
    "               'cup',\n",
    "               'pint',\n",
    "               'quart',\n",
    "               'gallon',\n",
    "               'drop',\n",
    "               'smidgen',\n",
    "               'pinch',\n",
    "               'dash',\n",
    "               'saltspoon',\n",
    "               'scruple',\n",
    "               'coffeespoon',\n",
    "               'dram',\n",
    "               'teaspoon',\n",
    "               'dessertspoon',\n",
    "               'tablespoon',\n",
    "               'fluid',\n",
    "               'ounce',\n",
    "               'wineglass',\n",
    "               'gill',\n",
    "               'teacup',\n",
    "               'tsp',\n",
    "               't',\n",
    "               'fl',\n",
    "               'oz',\n",
    "               'tbsp',\n",
    "               'dr',\n",
    "               'gt',\n",
    "               'gtt',\n",
    "               'smdg',\n",
    "               'smi',\n",
    "               'pn',\n",
    "               'ds',\n",
    "               'ssp',\n",
    "               'csp',\n",
    "               'dsp',\n",
    "               'dssp',\n",
    "               'dstspn',\n",
    "               'wgf',\n",
    "               'tcf',\n",
    "               'c',\n",
    "               'pt',\n",
    "               'qt',\n",
    "               'gal',\n",
    "               'minim',\n",
    "               'bu',\n",
    "               'bushel',\n",
    "               'gal',\n",
    "               'ml',\n",
    "               'milliliter',\n",
    "                'millilitre',\n",
    "                'centiliter',\n",
    "                'centilitre',\n",
    "                'centimeter',\n",
    "                'cl',\n",
    "                'kilogramme',\n",
    "                'gramme',\n",
    "                'milligramme',\n",
    "                '#',\n",
    "                'slice',\n",
    "                'heaped',\n",
    "                'halves',\n",
    "                'bulb',\n",
    "                'level',\n",
    "                'dl',\n",
    "                'deciliter',\n",
    "                'decilitre',\n",
    "               'l',\n",
    "               'liter',\n",
    "               'litre',\n",
    "               'pk',\n",
    "               'peck',\n",
    "               'tb',\n",
    "               'g',\n",
    "               'gram',\n",
    "               'kg',\n",
    "               'kilogram',\n",
    "               'lb',\n",
    "               'pound',\n",
    "               'mg',\n",
    "               'milligram',\n",
    "               'doz',\n",
    "               'dozen',\n",
    "               'lg',\n",
    "               'large',\n",
    "               'small',\n",
    "               'medium',\n",
    "               'sm',\n",
    "               'package',\n",
    "               'half',\n",
    "               'full',\n",
    "               'third',\n",
    "               'fourth',\n",
    "               'whole',\n",
    "               'inch',\n",
    "                'clove',\n",
    "                'bunch',\n",
    "                'container'\n",
    "               ]\n",
    "\n",
    "miscellaneous_words = ['refrigerated',\n",
    "                      'can',\n",
    "                      'canned',\n",
    "                      'fresh',\n",
    "                      'chopped',\n",
    "                      'skinless',\n",
    "                      'boneless',\n",
    "                      'kosher',\n",
    "                      'ground',\n",
    "                      'skin',\n",
    "                      'off',\n",
    "                      'on',\n",
    "                      'boil',\n",
    "                      'mild',\n",
    "                      'spicy',\n",
    "                      'cold',\n",
    "                      'warm',\n",
    "                      'grain',\n",
    "                      'spray',\n",
    "                      'cooking',\n",
    "                      'condensed',\n",
    "                      'bulk',\n",
    "                      'round',\n",
    "                      'loaf',\n",
    "                      'temperature',\n",
    "                      'wedge',\n",
    "                      'slice',\n",
    "                      'diced',\n",
    "                      'peeled',\n",
    "                      'zested',\n",
    "                      'juiced',\n",
    "                      'cooked',\n",
    "                      'lightly',\n",
    "                      'heavy',\n",
    "                      'whipped',\n",
    "                      'room',\n",
    "                      'sour',\n",
    "                      'sweet',\n",
    "                      'bunch',\n",
    "                      'floret',\n",
    "                      'mix',\n",
    "                      'dry',\n",
    "                      'seasoned',\n",
    "                      'prepared',\n",
    "                      'melted',\n",
    "                      'fried',\n",
    "                      'grilled',\n",
    "                      'sun',\n",
    "                      'dried',\n",
    "                      'pitted',\n",
    "                      'thawed',\n",
    "                      'lean',\n",
    "                      'skim',\n",
    "                      'fat-free',\n",
    "                      'fat',\n",
    "                      'free',\n",
    "                      'whole',\n",
    "                      'crumbled',\n",
    "                      'head',\n",
    "                      'root',\n",
    "                      'shredded',\n",
    "                      'pitted',\n",
    "                      'soft',\n",
    "                      'hard',\n",
    "                      'tail',\n",
    "                      'head',\n",
    "                      'rinsed',\n",
    "                      'spices',\n",
    "                      'thin',\n",
    "                      'thick-cut',\n",
    "                      'thick',\n",
    "                      'thin-cut',\n",
    "                      'cut',\n",
    "                      'beaten',\n",
    "                      'baked',\n",
    "                      'uncooked',\n",
    "                      'tin',\n",
    "                       'jar',\n",
    "                       'needed',\n",
    "                       'water',\n",
    "                       'sauce',\n",
    "                       'chunk',\n",
    "                       'dressing',\n",
    "                       'shoulder',\n",
    "                       'rib',\n",
    "                       'prime',\n",
    "                       'ground',\n",
    "                       'coarse',\n",
    "                       'fine',\n",
    "                       'leg',\n",
    "                       'foot',\n",
    "                       'liver',\n",
    "                       'tongue',\n",
    "                       'drained',\n",
    "                       'leftover',\n",
    "                       'frozen',\n",
    "                       'seeded',\n",
    "                       'roughly',\n",
    "                       'grated',\n",
    "                       'browned',\n",
    "                       'natural',\n",
    "                       'vegan',\n",
    "                       'powder',\n",
    "                       'baby',\n",
    "                       'optional',\n",
    "                       'bone',\n",
    "                       'finely',\n",
    "                       'torn',\n",
    "                       'pieces',\n",
    "                       'piece',\n",
    "                       'minced',\n",
    "                       'freshly'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "84c08d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredients(data, measurements, miscellaneous_words):\n",
    "    ### Takes list of ingredients as input and returns processed ingredients list ###\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    \n",
    "    # lemmatize list of measurements to remove\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for me in measurements:\n",
    "        me = lemmatizer.lemmatize(me)\n",
    "    for mi in miscellaneous_words:\n",
    "        mi = lemmatizer.lemmatize(mi)\n",
    "    \n",
    "    # set stopwords using nltk\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # iterate through each recipe's ingredients\n",
    "    for recipe1 in data_copy:\n",
    "        ingredients = recipe1.get('ingredients')\n",
    "        \n",
    "        ing_list = []\n",
    "        # iterate through all ingredients\n",
    "        for i in ingredients:\n",
    "            # get rid of punctuation\n",
    "            i = i.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            # turn string into list\n",
    "            i = i.split(' ')\n",
    "\n",
    "            # remove 'ADVERTISEMENT'\n",
    "            if 'ADVERTISEMENT' in i: i.remove('ADVERTISEMENT')\n",
    "\n",
    "            # remove any ints from measurements and non-alphabet words \n",
    "            i = [ing for ing in i if not ing.isdigit() or ing.isalpha()]\n",
    "\n",
    "            # turn to lowercase\n",
    "            i = [ing.lower() for ing in i]\n",
    "\n",
    "            # lemmatize word\n",
    "            i = [lemmatizer.lemmatize(ing) for ing in i]\n",
    "\n",
    "            # remove any measurement words\n",
    "            i = [ing for ing in i if ing not in measurements]\n",
    "\n",
    "            # remove any STOP words\n",
    "            i = [ing for ing in i if ing not in stop_words]\n",
    "\n",
    "            # remove any miscellaneous words\n",
    "            i = [ing for ing in i if ing not in miscellaneous_words]\n",
    "\n",
    "            # only append to ing list is non-empty\n",
    "            if i:\n",
    "                i_str = ' '.join(i)\n",
    "                ing_list.append(i_str)\n",
    "                \n",
    "        recipe1.update({'ingredients': ing_list})\n",
    "                \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9c444886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further processing of 'data_complete'\n",
    "clean_data = clean_ingredients(data_complete, measurements, miscellaneous_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8959c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most frequent ingredient strings: \n",
      "----------------\n",
      "salt  --> Count:  48473\n",
      "egg  --> Count:  23693\n",
      "olive oil  --> Count:  19389\n",
      "sugar  --> Count:  18784\n",
      "allpurpose flour  --> Count:  17418\n",
      "onion  --> Count:  15859\n",
      "butter  --> Count:  15683\n",
      "garlic  --> Count:  15618\n",
      "milk  --> Count:  13078\n",
      "cream  --> Count:  12136\n",
      "white sugar  --> Count:  10974\n",
      "vanilla extract  --> Count:  10602\n",
      "salt freshly black pepper  --> Count:  10526\n",
      "garlic minced  --> Count:  10146\n",
      "vegetable oil  --> Count:  9584\n"
     ]
    }
   ],
   "source": [
    "# see how top ingredients have changed\n",
    "exploration(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688eb359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03c1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf034e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b8f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
